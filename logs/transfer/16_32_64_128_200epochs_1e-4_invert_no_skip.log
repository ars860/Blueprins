Traceback (most recent call last):
  File "train_segmentation.py", line 163, in <module>
    train_segmentation(args)
  File "train_segmentation.py", line 103, in train_segmentation
    transfer_knowledge(model, Path() / 'learned_models' / args.transfer, device=args.device)
  File "train_segmentation.py", line 18, in transfer_knowledge
    state_dict = torch.load(knowledge_path, map_location=device)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 592, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 851, in _load
    result = unpickler.load()
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 843, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 832, in load_tensor
    loaded_storages[key] = restore_location(storage, location)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 809, in restore_location
    return default_restore_location(storage, map_location)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/_utils.py", line 80, in _cuda
    return new_type(self.size()).copy_(self, non_blocking)
  File "/nfs/home/asyuris/.local/lib/python3.7/site-packages/torch/cuda/__init__.py", line 484, in _lazy_new
    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
RuntimeError: CUDA error: out of memory
